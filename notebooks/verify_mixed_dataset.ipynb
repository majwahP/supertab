{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4e90b49d",
   "metadata": {},
   "source": [
    "# Verification mixed dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "291d68be",
   "metadata": {},
   "source": [
    "### This notebook thest the mixed-dataset dataloader to see if it gives corresponding patches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7b3585e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "\n",
    "import torch\n",
    "import zarr\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "import sys\n",
    "project_root = Path().resolve().parent\n",
    "sys.path.append(str(project_root))\n",
    "\n",
    "import zarr  # Optional, only used to debug if needed\n",
    "from supertrab.sr_dataset_utils import create_triplet_dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c705a3b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_patch_alignment_grid(zarr_path, group_name, num_samples=50, seed=42):\n",
    "    \"\"\"\n",
    "    Saves a single PNG showing a grid of QCT, HR-pQCT, and LR triplets side-by-side.\n",
    "    \"\"\"\n",
    "    zarr_path = Path(zarr_path)\n",
    "    z = zarr.open(str(zarr_path), mode=\"r\")[group_name]\n",
    "\n",
    "    qct = z[\"qct\"]\n",
    "    hrpqct = z[\"hrpqct\"]\n",
    "    lr = z[\"lr\"]\n",
    "\n",
    "    num_patches = len(qct)\n",
    "    assert len(hrpqct) == num_patches and len(lr) == num_patches, \"Patch count mismatch!\"\n",
    "\n",
    "    np.random.seed(seed)\n",
    "    indices = np.random.choice(range(num_patches), size=min(num_samples, num_patches), replace=False)\n",
    "\n",
    "    save_dir = Path(\"patch_outputs\")\n",
    "    save_dir.mkdir(parents=True, exist_ok=True)\n",
    "    save_path = save_dir / f\"{group_name}_grid.png\"\n",
    "\n",
    "    fig, axes = plt.subplots(nrows=num_samples, ncols=3, figsize=(10, 3 * num_samples))\n",
    "\n",
    "    for row_idx, idx in enumerate(indices):\n",
    "        patch_qct = torch.tensor(qct[idx]).squeeze(0)\n",
    "        patch_hr  = torch.tensor(hrpqct[idx]).squeeze(0)\n",
    "        patch_lr  = torch.tensor(lr[idx]).squeeze(0)\n",
    "\n",
    "        for col_idx, (img, title) in enumerate(zip(\n",
    "            [patch_qct, patch_hr, patch_lr], \n",
    "            [\"QCT\", \"HR-pQCT\", \"LR\"]\n",
    "        )):\n",
    "            ax = axes[row_idx, col_idx] if num_samples > 1 else axes[col_idx]\n",
    "            ax.imshow(img, cmap=\"gray\")\n",
    "            if row_idx == 0:\n",
    "                ax.set_title(title, fontsize=12)\n",
    "            ax.axis(\"off\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(save_path, dpi=150)\n",
    "    plt.close(fig)\n",
    "    print(f\"Saved grid image to: {save_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "074f5564",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved grid image to: patch_outputs/1996_R_grid.png\n"
     ]
    }
   ],
   "source": [
    "zarr_path = \"/usr/terminus/data-xrm-01/stamplab/external/tacosound/HR-pQCT_II/zarr_data/paired_patch_dataset.zarr\"\n",
    "group_name = \"1996_R\"\n",
    "test_patch_alignment_grid(zarr_path, group_name, num_samples=50)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ae50e4f",
   "metadata": {},
   "source": [
    "# Test correspondence when loading from dataloder - several groups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "ae457bed",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_random_triplets_from_dataloader(zarr_path, num_samples=10, batch_size=1, seed=42, save_path=\"patch_outputs/mixed_groups_grid.png\"):\n",
    "    \"\"\"\n",
    "    Sample random triplets (QCT, HR, LR) from a multi-group dataset and save a grid PNG.\n",
    "    \"\"\"\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "\n",
    "    # Load dataset & dataloader\n",
    "    conditioning_mode = \"mix\"  #\"qct\"  or \"mix\"\n",
    "    groups = [\"1955_L\", \"1956_L\", \"1996_R\", \"2005_L\"]\n",
    "    dataloader = create_triplet_dataloader(zarr_path, groups, conditioning_mode=conditioning_mode, patch_size=(1, 256, 256), batch_size=4)\n",
    "\n",
    "\n",
    "    save_path = Path(save_path)\n",
    "    save_path.parent.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    collected = []\n",
    "    for batch in dataloader:\n",
    "        for i in range(batch_size):\n",
    "            collected.append({\n",
    "                \"qct\": batch[\"qct\"][i].squeeze(0),\n",
    "                \"hr\": batch[\"hr_image\"][i].squeeze(0),\n",
    "                \"lr\": batch[\"lr\"][i].squeeze(0),\n",
    "                \"group\": batch[\"group\"][i],\n",
    "                \"index\": batch[\"index\"][i].item(),\n",
    "            })\n",
    "            if len(collected) >= num_samples:\n",
    "                break\n",
    "        if len(collected) >= num_samples:\n",
    "            break\n",
    "\n",
    "    # Plot grid\n",
    "    fig, axes = plt.subplots(nrows=num_samples, ncols=3, figsize=(10, 3 * num_samples))\n",
    "    group_str = []\n",
    "    index_str = []\n",
    "\n",
    "    for row_idx, sample in enumerate(collected):\n",
    "        for col_idx, (img, title) in enumerate(zip(\n",
    "            [sample[\"qct\"], sample[\"hr\"], sample[\"lr\"]],\n",
    "            [\"QCT\", \"HR-pQCT\", \"LR\"]\n",
    "        )):\n",
    "            ax = axes[row_idx, col_idx] if num_samples > 1 else axes[col_idx]\n",
    "            ax.imshow(img, cmap=\"gray\")\n",
    "            if row_idx == 0:\n",
    "                ax.set_title(title, fontsize=12)\n",
    "            ax.axis(\"off\")\n",
    "\n",
    "        group_str.append(sample[\"group\"])\n",
    "        index_str.append(sample[\"index\"])\n",
    "        # axes[row_idx, 0].set_ylabel(f\"{group_str}\\n#{index_str}\", fontsize=10)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    # plt.show()\n",
    "    plt.savefig(save_path, dpi=150)\n",
    "    plt.close(fig)\n",
    "    print(f\"✅ Saved multi-group patch grid to: {save_path}\")\n",
    "    print(group_str)\n",
    "    print(index_str)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "33fc97d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Saved multi-group patch grid to: patch_outputs/mixed_groups_grid_2.png\n",
      "['1996_R', '1956_L', '2005_L', '1996_R', '1996_R', '1955_L', '1956_L', '2005_L', '1955_L', '1996_R', '1996_R', '1955_L', '1996_R', '1955_L', '1955_L', '1955_L', '1955_L', '2005_L', '1996_R', '1955_L', '1996_R', '1996_R', '2005_L', '2005_L', '1955_L', '2005_L', '1955_L', '1955_L', '1955_L', '1955_L', '2005_L', '1996_R', '2005_L', '1956_L', '1955_L', '2005_L', '1955_L', '2005_L', '1956_L', '2005_L', '2005_L', '1955_L', '1955_L', '1956_L', '1955_L', '1956_L', '1955_L', '2005_L', '1955_L', '1955_L']\n",
      "[5679, 20799, 7917, 16720, 8247, 20125, 12008, 3772, 599, 13185, 11319, 50859, 15747, 33156, 45750, 19569, 49665, 22093, 9227, 37733, 3955, 14298, 7848, 9682, 15450, 15874, 34806, 4250, 44540, 6176, 12743, 3729, 8510, 11317, 22661, 13615, 1263, 11686, 16176, 15882, 8034, 7624, 3848, 21529, 39475, 17881, 12431, 19194, 11234, 27041]\n"
     ]
    }
   ],
   "source": [
    "zarr_path = \"/usr/terminus/data-xrm-01/stamplab/external/tacosound/HR-pQCT_II/zarr_data/paired_patch_dataset.zarr\"\n",
    "\n",
    "sample_random_triplets_from_dataloader(\n",
    "    zarr_path=zarr_path,\n",
    "    num_samples=50,  # number of rows in the image\n",
    "    seed=52,\n",
    "    batch_size=2,\n",
    "    save_path=\"patch_outputs/mixed_groups_grid_2.png\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ff99416",
   "metadata": {},
   "source": [
    "# Generate as in training loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "1a00c63b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def plot_hr_conditioning_pairs_from_dataloader(\n",
    "    dataloader,\n",
    "    conditioning_mode=\"mix\",\n",
    "    num_pairs=50,\n",
    "    save_path=\"patch_outputs/hr_conditioning_grid.png\",\n",
    "    seed=50\n",
    "):\n",
    "    \"\"\"\n",
    "    Sample HR and conditioning image pairs from a dataloader and save as a grid image.\n",
    "    No air filtering — assumes it was already applied during dataset creation.\n",
    "    \"\"\"\n",
    "    def scale(x):\n",
    "        x_min = x.amin(dim=(-2, -1), keepdim=True)\n",
    "        x_max = x.amax(dim=(-2, -1), keepdim=True)\n",
    "        return (x - x_min) / (x_max - x_min + 1e-8)\n",
    "\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "\n",
    "    collected = []\n",
    "    for batch in dataloader:\n",
    "        clean_images = batch[\"hr_image\"]\n",
    "\n",
    "        if conditioning_mode == \"qct\":\n",
    "            conditioning = batch[\"qct\"]\n",
    "        elif conditioning_mode == \"lr\":\n",
    "            conditioning = batch[\"lr\"]\n",
    "        elif conditioning_mode == \"mix\":\n",
    "            rand_mask = torch.rand(clean_images.size(0), device=clean_images.device) < 0.5\n",
    "            conditioning = torch.where(\n",
    "                rand_mask[:, None, None, None],\n",
    "                batch[\"qct\"],\n",
    "                batch[\"lr\"]\n",
    "            )\n",
    "        else:\n",
    "            raise ValueError(f\"Unsupported conditioning_mode: {conditioning_mode}\")\n",
    "\n",
    "        # Normalize for visualization\n",
    "        conditioning = scale(conditioning)\n",
    "        clean_images = scale(clean_images)\n",
    "\n",
    "        for i in range(clean_images.shape[0]):\n",
    "            collected.append({\n",
    "                \"hr\": clean_images[i].squeeze(0).cpu(),\n",
    "                \"cond\": conditioning[i].squeeze(0).cpu()\n",
    "            })\n",
    "            if len(collected) >= num_pairs:\n",
    "                break\n",
    "        if len(collected) >= num_pairs:\n",
    "            break\n",
    "\n",
    "    # Plot grid\n",
    "    save_path = Path(save_path)\n",
    "    save_path.parent.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    fig, axes = plt.subplots(nrows=num_pairs, ncols=2, figsize=(6, 2.5 * num_pairs))\n",
    "    for i, pair in enumerate(collected):\n",
    "        axes[i, 0].imshow(pair[\"hr\"], cmap=\"gray\")\n",
    "        axes[i, 0].set_title(\"HR-pQCT\")\n",
    "        axes[i, 0].axis(\"off\")\n",
    "\n",
    "        axes[i, 1].imshow(pair[\"cond\"], cmap=\"gray\")\n",
    "        axes[i, 1].set_title(\"Conditioning\")\n",
    "        axes[i, 1].axis(\"off\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(save_path, dpi=150)\n",
    "    plt.close(fig)\n",
    "    print(f\"✅ Saved HR-conditioning pair grid to: {save_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "ad7bf21c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Saved HR-conditioning pair grid to: patch_outputs/hr_conditioning_grid.png\n"
     ]
    }
   ],
   "source": [
    "zarr_path = \"/usr/terminus/data-xrm-01/stamplab/external/tacosound/HR-pQCT_II/zarr_data/paired_patch_dataset.zarr\"\n",
    "group_names = [\"1955_L\", \"1956_L\", \"1996_R\", \"2005_L\"]\n",
    "conditioning_mode = \"mix\"\n",
    "\n",
    "train_dataloader = create_triplet_dataloader(\n",
    "    zarr_path=zarr_path,\n",
    "    group_names=group_names,\n",
    "    conditioning_mode=conditioning_mode,\n",
    "    patch_size=(1, 256, 256),\n",
    "    batch_size=8\n",
    ")\n",
    "\n",
    "plot_hr_conditioning_pairs_from_dataloader(\n",
    "    dataloader=train_dataloader,\n",
    "    conditioning_mode=conditioning_mode,\n",
    "    num_pairs=30,\n",
    "    save_path=\"patch_outputs/hr_conditioning_grid.png\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "624fdc16",
   "metadata": {},
   "source": [
    "# use dataloaders mix function"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7bebae9",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "070b3ac8",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def plot_hr_conditioning_pairs_from_dataloader_dataloadermix(\n",
    "    dataloader,\n",
    "    num_pairs=50,\n",
    "    save_path=\"patch_outputs/hr_conditioning_grid.png\",\n",
    "):\n",
    "    \"\"\"\n",
    "    Sample HR and conditioning image pairs from a dataloader and save as a grid image.\n",
    "    No air filtering — assumes it was already applied during dataset creation.\n",
    "    \"\"\"\n",
    "\n",
    "    collected = []\n",
    "    for batch in dataloader:\n",
    "        clean_images = batch[\"hr_image\"]\n",
    "        conditioning = batch[\"conditioning\"]\n",
    "\n",
    "        for i in range(clean_images.shape[0]):\n",
    "            cond_source = \"Unknown\"\n",
    "            if conditioning_mode == \"mix\":\n",
    "                if torch.allclose(conditioning[i], batch[\"qct\"][i]):\n",
    "                    cond_source = \"QCT\"\n",
    "                elif torch.allclose(conditioning[i], batch[\"lr\"][i]):\n",
    "                    cond_source = \"LR\"\n",
    "                print(f\"[{batch['group'][i]} #{batch['index'][i]}] Used {cond_source} as conditioning\")\n",
    "\n",
    "            collected.append({\n",
    "                \"hr\": clean_images[i].squeeze(0).cpu(),\n",
    "                \"cond\": conditioning[i].squeeze(0).cpu(),\n",
    "            })\n",
    "\n",
    "            if len(collected) >= num_pairs:\n",
    "                break\n",
    "        if len(collected) >= num_pairs:\n",
    "            break\n",
    "\n",
    "    # Plot grid\n",
    "    save_path = Path(save_path)\n",
    "    save_path.parent.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    fig, axes = plt.subplots(nrows=num_pairs, ncols=2, figsize=(6, 2.5 * num_pairs))\n",
    "    for i, pair in enumerate(collected):\n",
    "        axes[i, 0].imshow(pair[\"hr\"], cmap=\"gray\")\n",
    "        axes[i, 0].set_title(\"HR-pQCT\")\n",
    "        axes[i, 0].axis(\"off\")\n",
    "\n",
    "        axes[i, 1].imshow(pair[\"cond\"], cmap=\"gray\")\n",
    "        axes[i, 1].set_title(\"Conditioning\")\n",
    "        axes[i, 1].axis(\"off\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(save_path, dpi=150)\n",
    "    plt.close(fig)\n",
    "    print(f\"✅ Saved HR-conditioning pair grid to: {save_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "b82e1e1e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1956_L #21320] Used QCT as conditioning\n",
      "[1956_L #10277] Used QCT as conditioning\n",
      "[1996_R #5627] Used LR as conditioning\n",
      "[1996_R #3405] Used QCT as conditioning\n",
      "[1996_R #16110] Used QCT as conditioning\n",
      "[1955_L #27451] Used QCT as conditioning\n",
      "[1955_L #13900] Used QCT as conditioning\n",
      "[1955_L #42294] Used QCT as conditioning\n",
      "[1955_L #30380] Used LR as conditioning\n",
      "[1996_R #15155] Used QCT as conditioning\n",
      "[1955_L #9807] Used LR as conditioning\n",
      "[1955_L #36390] Used QCT as conditioning\n",
      "[1955_L #11780] Used LR as conditioning\n",
      "[2005_L #9917] Used LR as conditioning\n",
      "[1955_L #1660] Used LR as conditioning\n",
      "[2005_L #11508] Used LR as conditioning\n",
      "[1955_L #40883] Used LR as conditioning\n",
      "[1955_L #15650] Used LR as conditioning\n",
      "[1955_L #20628] Used QCT as conditioning\n",
      "[1996_R #3565] Used LR as conditioning\n",
      "[1996_R #14847] Used LR as conditioning\n",
      "[2005_L #21558] Used LR as conditioning\n",
      "[1955_L #5368] Used QCT as conditioning\n",
      "[1956_L #18716] Used QCT as conditioning\n",
      "[1996_R #16981] Used LR as conditioning\n",
      "[1956_L #20694] Used LR as conditioning\n",
      "[1956_L #18613] Used LR as conditioning\n",
      "[1955_L #35516] Used LR as conditioning\n",
      "[1956_L #22550] Used QCT as conditioning\n",
      "[2005_L #17099] Used LR as conditioning\n",
      "✅ Saved HR-conditioning pair grid to: patch_outputs/hr_conditioning_grid_dataloader_mix.png\n"
     ]
    }
   ],
   "source": [
    "zarr_path = \"/usr/terminus/data-xrm-01/stamplab/external/tacosound/HR-pQCT_II/zarr_data/paired_patch_dataset.zarr\"\n",
    "group_names = [\"1955_L\", \"1956_L\", \"1996_R\", \"2005_L\"]\n",
    "conditioning_mode = \"mix\"\n",
    "\n",
    "train_dataloader = create_triplet_dataloader(\n",
    "    zarr_path=zarr_path,\n",
    "    group_names=group_names,\n",
    "    conditioning_mode=conditioning_mode,\n",
    "    patch_size=(1, 256, 256),\n",
    "    batch_size=8, \n",
    "    num_workers=0\n",
    ")\n",
    "\n",
    "plot_hr_conditioning_pairs_from_dataloader_dataloadermix(\n",
    "    dataloader=train_dataloader,\n",
    "    num_pairs=30,\n",
    "    save_path=\"patch_outputs/hr_conditioning_grid_dataloader_mix.png\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ML_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
